seq2seq:
    input_dim: 10000
    output_dim: 10000
    emb_dim: 256
    hidden_dim: 512
    n_layers: 2
    dropout_ratio: 0.5


attention:
    input_dim: 10000
    output_dim: 10000
    emb_dim: 256
    hidden_dim: 512
    dropout_ratio: 0.5


transformer:
    input_dim: 10000
    output_dim: 10000
    emb_dim: 256
    hidden_dim: 256
    pff_dim: 512
    n_layers: 3
    n_heads: 8
    dropout_ratio: 0.1